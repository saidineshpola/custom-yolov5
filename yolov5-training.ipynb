{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from ray import tune\n",
    "\n",
    "# Define a YOLO model\n",
    "model = YOLO(\"yolov8l-cls.pt\",)\n",
    "\n",
    "# Run Ray Tune on the model\n",
    "result_grid = model.tune(\n",
    "    data=\"datasets/crop-datasets/classify-generated/val\",\n",
    "    dropout=0.2,\n",
    "    label_smoothing=0.1,\n",
    "    space={\"lr0\": tune.uniform(1e-5, 1e-1),\n",
    "           \"imgsz\": tune.choice([480, 512, 600, 640]),\n",
    "           \"optimizer\": tune.choice([\"adam\", \"sgd\", \"AdamW\", \"RMSProp\"]),\n",
    "           },\n",
    "    batch=12,\n",
    "    epochs=20,\n",
    "    use_ray=True, name='yolov5l-cls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean and STD of mosquito data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 622/622 [01:52<00:00,  5.53it/s]\n",
      "100%|██████████| 47/47 [00:04<00:00, 11.73it/s]\n",
      "100%|██████████| 4612/4612 [04:28<00:00, 17.17it/s]\n",
      "100%|██████████| 429/429 [00:49<00:00,  8.72it/s]\n",
      "100%|██████████| 84/84 [00:04<00:00, 19.39it/s]\n",
      "100%|██████████| 4563/4563 [05:12<00:00, 14.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [138.36356524 148.52860967 161.277854  ]\n",
      "Standard Deviation: [53.20503549 49.51324015 48.71902218]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "def calculate_mean_and_std(folder_path):\n",
    "    # Initialize variables to store mean and std\n",
    "    total_pixels = 0\n",
    "    pixel_sum = np.zeros(3)\n",
    "    pixel_sum_squared = np.zeros(3)\n",
    "\n",
    "    # Iterate through the folder and its subfolders\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in tqdm(files):\n",
    "            if file.lower().endswith(\".jpeg\"):\n",
    "                # Read the image using OpenCV\n",
    "                image_path = os.path.join(root, file)\n",
    "                image = cv2.imread(image_path)\n",
    "\n",
    "                # Convert to float to avoid overflow when summing large images\n",
    "                image = image.astype(float)\n",
    "\n",
    "                # Add pixel values to the sum\n",
    "                pixel_sum += np.sum(image, axis=(0, 1))\n",
    "                pixel_sum_squared += np.sum(image ** 2, axis=(0, 1))\n",
    "                total_pixels += image.shape[0] * image.shape[1]\n",
    "\n",
    "    # Calculate the mean and standard deviation\n",
    "    mean = pixel_sum / total_pixels\n",
    "    std = np.sqrt(pixel_sum_squared / total_pixels - (mean ** 2))\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "# Specify the folder path\n",
    "folder_path = \"/home/saidinesh/Desktop/Projects/yolov5/datasets/classify-crop/train\"\n",
    "\n",
    "# Call the function to calculate mean and std\n",
    "mean, std = calculate_mean_and_std(folder_path)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"Standard Deviation: {std}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mean=[138.36356524/255,148.52860967/255,161.277854/255]\n",
    "STD= [53.20503549/255,49.51324015/255,48.71902218/255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.542602216627451, 0.5824651359607843, 0.6324621725490196]\n",
      "[0.208647198, 0.1941695692156863, 0.19105498894117648]\n"
     ]
    }
   ],
   "source": [
    "Mean= [138.36356524, 148.52860967, 161.277854  ]\n",
    "Standard_Deviation=[53.20503549, 49.51324015 ,48.71902218]\n",
    "# Now convert them to normalized\n",
    "Mean = [item / 255 for item in Mean]\n",
    "Standard_Deviation = [item / 255 for item in Standard_Deviation]\n",
    "print(Mean)\n",
    "print(Standard_Deviation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Croped Images dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9840/9840 [09:55<00:00, 16.52it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "from tqdm import tqdm \n",
    "# Path to the YOLO dataset Change based on Train and Test\n",
    "yolo_dataset_path = '/home/saidinesh/Desktop/Projects/yolov5/datasets/train'\n",
    "yolo_dataset_path_val='/home/saidinesh/Desktop/Projects/yolov5/datasets/val'\n",
    "# Path to the image classification dataset\n",
    "image_classification_path = '/home/saidinesh/Desktop/Projects/yolov5/datasets/classify-crop'\n",
    "\n",
    "# List of class names\n",
    "class_names = ['aegypti', 'albopictus', 'anopheles', 'culex', 'culiseta', 'japonicus-koreicus']\n",
    "\n",
    "# Create class directories in train and val folders\n",
    "for class_name in class_names:\n",
    "    os.makedirs(os.path.join(image_classification_path, 'train/images', class_name), exist_ok=True)\n",
    "    os.makedirs(os.path.join(image_classification_path, 'val/images', class_name), exist_ok=True)\n",
    "\n",
    "def crop_dataset(yolo_dataset_path=yolo_dataset_path):\n",
    "    # Copy cropped object images to the appropriate class folders in train and val\n",
    "    for root, _, files in os.walk(os.path.join(yolo_dataset_path, 'images')):\n",
    "        for file in tqdm(files):\n",
    "            image_path = os.path.join(root, file)\n",
    "            label_path = os.path.join(yolo_dataset_path, 'labels', os.path.splitext(file)[0] + '.txt')\n",
    "            if not os.path.exists(label_path):\n",
    "                continue\n",
    "            # Read the label file to check the object's class\n",
    "            with open(label_path, 'r') as label_file:\n",
    "                line = label_file.readline().strip().split()\n",
    "                if len(line) == 5:  # YOLO format: class x_center y_center width height\n",
    "                    class_id = int(line[0])\n",
    "\n",
    "                    # Get the class name based on class_id\n",
    "                    if class_id < len(class_names):\n",
    "                        class_name = class_names[class_id]\n",
    "\n",
    "                        # Decide whether to put the image in train or val\n",
    "                        if 'train' in root:\n",
    "                            destination_folder = os.path.join(image_classification_path, 'train/images', class_name)\n",
    "                        else:\n",
    "                            destination_folder = os.path.join(image_classification_path, 'val/images', class_name)\n",
    "\n",
    "                        # Read the original image\n",
    "                        image = cv2.imread(image_path)\n",
    "\n",
    "                        # Extract bounding box coordinates\n",
    "                        x_center = float(line[1]) * image.shape[1]\n",
    "                        y_center = float(line[2]) * image.shape[0]\n",
    "                        width = float(line[3]) * image.shape[1]\n",
    "                        height = float(line[4]) * image.shape[0]\n",
    "\n",
    "                        # Calculate bounding box coordinates\n",
    "                        x1 = int(x_center - width / 2)\n",
    "                        y1 = int(y_center - height / 2)\n",
    "                        x2 = int(x_center + width / 2)\n",
    "                        y2 = int(y_center + height / 2)\n",
    "\n",
    "                        # Crop the object from the image\n",
    "                        cropped_object = image[y1:y2, x1:x2]\n",
    "\n",
    "                        # Save the cropped object as a new image\n",
    "                        object_filename = os.path.splitext(file)[0] + '.jpeg'\n",
    "                        object_path = os.path.join(destination_folder, object_filename)\n",
    "                        cv2.imwrite(object_path, cropped_object)\n",
    "\n",
    "crop_dataset(yolo_dataset_path)\n",
    "crop_dataset(yolo_dataset_path_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image classification dataset structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset conversion completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the paths and class labels\n",
    "dataset_path = \"/home/saidinesh/Desktop/Projects/yolov5/datasets/\"\n",
    "class_labels = [\"aegypti\", \"albopictus\", \"anopheles\", \"culex\", \"culiseta\", \"japonicus-koreicus\"]\n",
    "class_count = len(class_labels)\n",
    "\n",
    "# Define the train and validation directories\n",
    "train_image_dir = os.path.join(dataset_path, \"train/images/\")\n",
    "val_image_dir = os.path.join(dataset_path, \"val/images/\")\n",
    "labels_dir = os.path.join(dataset_path, \"val/labels/\")\n",
    "\n",
    "# Create class directories if they don't exist\n",
    "for label in class_labels:\n",
    "    os.makedirs(os.path.join(train_image_dir, label), exist_ok=True)\n",
    "    os.makedirs(os.path.join(val_image_dir, label), exist_ok=True)\n",
    "\n",
    "# Function to parse YOLO annotation files and copy images to the appropriate class folders\n",
    "def process_annotation(annotation_file, image_path, output_dir):\n",
    "    with open(annotation_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        if len(lines) > 0:\n",
    "            line = lines[0].strip().split()\n",
    "            if len(line) > 0:\n",
    "                class_index = int(line[0])\n",
    "                if class_index >= 0 and class_index < class_count:\n",
    "                    class_label = class_labels[class_index]\n",
    "                    output_class_dir = os.path.join(output_dir, class_label)\n",
    "                    output_image_path = os.path.join(output_class_dir, os.path.basename(image_path))\n",
    "                    if not os.path.exists(output_image_path):  # Check if the file exists before copying\n",
    "                        shutil.copy(image_path, output_image_path)\n",
    "\n",
    "# # Process train images and annotations\n",
    "# for root, _, files in os.walk(train_image_dir):\n",
    "#     for file in files:\n",
    "#         if file.endswith(\".jpeg\"):\n",
    "#             image_path = os.path.join(root, file)\n",
    "#             annotation_path = os.path.join(labels_dir, file.replace(\".jpeg\", \".txt\"))\n",
    "#             process_annotation(annotation_path, image_path, train_image_dir)\n",
    "\n",
    "# Process validation images and annotations\n",
    "for root, _, files in os.walk(val_image_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jpeg\"):\n",
    "            image_path = os.path.join(root, file)\n",
    "            annotation_path = os.path.join(labels_dir, file.replace(\".jpeg\", \".txt\"))\n",
    "            process_annotation(annotation_path, image_path, val_image_dir)\n",
    "\n",
    "print(\"Dataset conversion completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation creaation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:00<00:00, 19.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591\n",
      "45\n",
      "4381\n",
      "407\n",
      "80\n",
      "4335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 15.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0% of the images have been moved to the validation dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from tqdm import tqdm \n",
    "random.seed(43)\n",
    "\n",
    "# Define the path to your dataset folders\n",
    "train_folder = '/home/saidinesh/Desktop/Projects/yolov5/datasets/crop-datasets/ensemble1/train/'\n",
    "validation_folder = '/home/saidinesh/Desktop/Projects/yolov5/datasets/crop-datasets/ensemble1/val/'\n",
    "\n",
    "# Define the percentage of data to move to the validation dataset\n",
    "validation_percentage = 0.05\n",
    "\n",
    "# Iterate through each class folder in the train dataset\n",
    "for class_name in tqdm(os.listdir(train_folder)):\n",
    "\n",
    "    class_path = os.path.join(train_folder, class_name)\n",
    "    \n",
    "    # Get a list of all files (images) in the class folder\n",
    "    files = os.listdir(class_path)\n",
    "    print(len(files))\n",
    "    # Calculate the number of files to move to the validation dataset\n",
    "    num_files_to_move = int(validation_percentage * len(files))\n",
    "    \n",
    "    # Randomly select files to move\n",
    "    files_to_move = random.sample(files, num_files_to_move)\n",
    "    \n",
    "    # Move selected files to the validation dataset\n",
    "    for file_name in files_to_move:\n",
    "        file_path = os.path.join(class_path, file_name)\n",
    "        destination_path = os.path.join(validation_folder, class_name, file_name)\n",
    "        \n",
    "        # Create the destination directory if it doesn't exist\n",
    "        os.makedirs(os.path.dirname(destination_path), exist_ok=True)\n",
    "        \n",
    "        # Move the file\n",
    "        shutil.move(file_path, destination_path)\n",
    "\n",
    "print(f\"{validation_percentage * 100}% of the images have been moved to the validation dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ultralytics import RTDETR \n",
    "model = RTDETR('runs/detect/rt-detr-l-640/weights/last.pt',) # build from YAML and transfer weights\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data='datasets/dataset.yaml',amp=False,\n",
    "                      cache=True,\n",
    "                      batch=4,\n",
    "                       epochs=72, imgsz=640,resume='runs/detect/rt-detr-l-640/weights/last.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yolov5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train YOLOv5s on COCO128 for 3 epochs\n",
    "%cd /home/saidinesh/Desktop/Projects/yolov5/\n",
    "!python train.py --img 640 --cfg models/yolo-tph.yaml --batch 2 --epochs 100 --data datasets/dataset.yaml --weights yolov5s.pt --cache --name \"yolov5s-tph\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predictions exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# Run the model on GPU if it is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train/baseline-yolov5s/weights/last.pt')\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python detect.py --weights runs/train/baseline-yolov5s/weights/last.pt \\\n",
    "    --data datasets/dataset.yaml \\\n",
    "    --source datasets/val/images --save-txt --save-conf \\\n",
    "    --img 640 --half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "name = \"my-dataset\"\n",
    "dataset_dir = \"datasets/\"\n",
    "\n",
    "# The splits to load\n",
    "splits = [\"train\", \"val\"]\n",
    "try:\n",
    "    dataset = fo.load_dataset(name)\n",
    "    dataset.delete()\n",
    "except:\n",
    "    pass\n",
    "dataset = fo.Dataset(name)    \n",
    "for split in splits:\n",
    "    dataset.add_dir(\n",
    "        dataset_dir=dataset_dir,\n",
    "        dataset_type=fo.types.YOLOv5Dataset,\n",
    "        split=split,\n",
    "        tags=split,\n",
    ")\n",
    "\n",
    "# Get some summary information about the dataset\n",
    "print(dataset.info)\n",
    "print(dataset.stats)\n",
    "session = fo.Session(dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████████████| 0/0 [46.9us elapsed, ? remaining, ? samples/s]  100% |█████████████████████| 0/0 [2.5ms elapsed, ? remaining, ? samples/s]  \n",
      " 100% |█████████████████████| 0/0 [3.1ms elapsed, ? remaining, ? samples/s]  \n",
      "datasetInfo\n",
      "{}\n",
      " 100% |█████████████████████| 0/0 [5.1ms elapsed, ? remaining, ? samples/s] \n",
      "Finished adding predictions to the test_view\n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "from PIL import Image\n",
    "from torchvision.transforms import functional as func\n",
    "\n",
    "name = \"my-dataset\"\n",
    "dataset_dir = \"datasets/\"\n",
    "\n",
    "# The splits to load\n",
    "splits = [\"train\", \"val\"]\n",
    "try:\n",
    "    dataset = fo.load_dataset(name)\n",
    "    dataset.delete()\n",
    "except:\n",
    "    pass\n",
    "dataset = fo.Dataset(name)    \n",
    "for split in splits:\n",
    "    dataset.add_dir(\n",
    "        dataset_dir=dataset_dir,\n",
    "        dataset_type=fo.types.YOLOv5Dataset,\n",
    "        split=split,\n",
    "        tags=split,\n",
    ")\n",
    "\n",
    "# Get some summary information about the dataset\n",
    "print('datasetInfo')\n",
    "print(dataset.info)\n",
    "# print(dataset.stats)\n",
    "#session = fo.Session(dataset=dataset)\n",
    "\n",
    "\n",
    "\n",
    "# Get class list\n",
    "classes = dataset.default_classes\n",
    "test_view = dataset.match_tags(\"val\")\n",
    "# Add predictions to samples\n",
    "with fo.ProgressBar() as pb:\n",
    "    for sample in pb(test_view):\n",
    "        # Load image\n",
    "        image = Image.open(sample.filepath)\n",
    "\n",
    "        # Perform inference\n",
    "        preds = model(image)\n",
    "        pd  = preds.pandas().xyxy[0]\n",
    "\n",
    "        image = func.to_tensor(image).to(device)\n",
    "        c, h, w = image.shape\n",
    "\n",
    "        detections = []\n",
    "\n",
    "        for i in pd.values: \n",
    "            x1, y1, x2, y2 = i[0],i[1],i[2],i[3]\n",
    "            rel_box = [x1 / w, y1 / h, (x2 - x1) / w, (y2 - y1) / h]\n",
    "\n",
    "            detections.append(\n",
    "                fo.Detection(\n",
    "                    label=classes[i[5]],\n",
    "                    bounding_box=rel_box,\n",
    "                    confidence=i[4]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Save predictions to dataset\n",
    "        sample[\"predictions\"] = fo.Detections(detections=detections)\n",
    "        sample.save()\n",
    "\n",
    "print(\"Finished adding predictions to the test_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_view.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training CV model with kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/saidinesh/Desktop/Projects/yolov5/\n",
    "from ultralytics import YOLO\n",
    "weights_path = 'runs/detect/yolo-v5s-base_fold_4/weights/last.pt'\n",
    "results = {}\n",
    "for k in range(4,5):\n",
    "    model = YOLO(weights_path, task='detect')\n",
    "    dataset_yaml = f'datasets/train/2023-08-30_5-Fold_Cross-val/split_{k+1}/split_{k+1}_dataset.yaml' #ds_yamls[k]\n",
    "    model.train(data=dataset_yaml,name = f'yolo-v5s-base_fold_{k}',device=0,batch=8,resume=True)  # Include any training arguments\n",
    "    results[k] = model.metrics  # save output metrics for further analysis\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Completed Successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the paths to the val and train folders\n",
    "val_folder = '/home/saidinesh/Desktop/Projects/yolov5/datasets/val/images'\n",
    "train_folder = '/home/saidinesh/Desktop/Projects/yolov5/datasets/train/images'\n",
    "\n",
    "# Get a list of filenames in both folders\n",
    "val_files = os.listdir(val_folder)\n",
    "train_files = os.listdir(train_folder)\n",
    "\n",
    "# Find common filenames between the two folders\n",
    "common_files = set(val_files) & set(train_files)\n",
    "\n",
    "# Move common files from train to val folder\n",
    "for filename in common_files:\n",
    "    src_path = os.path.join(train_folder, filename)\n",
    "    dest_path = os.path.join(val_folder, filename)\n",
    "    \n",
    "    # Check if the file already exists in the val folder\n",
    "    if os.path.exists(dest_path):\n",
    "        shutil.move(src_path, dest_path)\n",
    "        print(f\"Moved '{filename}' from train to val folder.\")\n",
    "        \n",
    "\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
