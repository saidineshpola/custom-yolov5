{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yolo V5 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train YOLOv5s on COCO128 for 3 epochs\n",
    "%cd /home/saidinesh/Desktop/Projects/yolov5/\n",
    "\n",
    "!python train.py --img 640  --hyp 'data/hyps/hyp.scratch-low.yaml' \\\n",
    "    --batch 4 --epochs 100 --data datasets/dataset.yaml --weights yolov5x.pt --cache --name \"yoloV5x-local-640\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kfold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r datasets/val/labels datasets/train/labels\n",
    "!cp -r datasets/val/images datasets/train/images\n",
    "# !mv /content/dataset/val/ /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from sklearn.model_selection import KFold\n",
    "dataset_path = Path('/home/saidinesh/Desktop/Projects/yolov5/datasets/train/') # replace with 'path/to/dataset' for your custom data\n",
    "labels = sorted(dataset_path.rglob(\"*labels/*.txt\")) # all data in 'labels'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from sklearn.model_selection import KFold\n",
    "dataset_path = Path('/home/saidinesh/Desktop/Projects/yolov5/datasets/train/') # replace with 'path/to/dataset' for your custom data\n",
    "labels = sorted(dataset_path.rglob(\"*labels/*.txt\")) # all data in 'labels'\n",
    "\n",
    "with open('datasets/dataset.yaml', 'r', encoding=\"utf8\") as y:\n",
    "    classes = yaml.safe_load(y)['names']\n",
    "cls_idx = sorted(classes)\n",
    "cls_idx = [0,1,2,3,4,5]\n",
    "indx = [l.stem for l in labels] # uses base filename as ID (no extension)\n",
    "labels_df = pd.DataFrame([], columns=cls_idx, index=indx)\n",
    "for label in labels:\n",
    "    lbl_counter = Counter()\n",
    "\n",
    "    with open(label,'r') as lf:\n",
    "        lines = lf.readlines()\n",
    "\n",
    "    for l in lines:\n",
    "        # classes for YOLO label uses integer at first position of each line\n",
    "        lbl_counter[int(l.split(' ')[0])] += 1\n",
    "\n",
    "    labels_df.loc[label.stem] = lbl_counter\n",
    "\n",
    "labels_df = labels_df.fillna(0.0) # replace `nan` values with `0.0`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksplit = 5\n",
    "kf = KFold(n_splits=ksplit, shuffle=True, random_state=20)   # setting random_state for repeatable results\n",
    "\n",
    "kfolds = list(kf.split(labels_df))\n",
    "folds = [f'split_{n}' for n in range(1, ksplit + 1)]\n",
    "folds_df = pd.DataFrame(index=indx, columns=folds)\n",
    "\n",
    "for idx, (train, val) in enumerate(kfolds, start=1):\n",
    "    folds_df[f'split_{idx}'].loc[labels_df.iloc[train].index] = 'train'\n",
    "    folds_df[f'split_{idx}'].loc[labels_df.iloc[val].index] = 'val'\n",
    "fold_lbl_distrb = pd.DataFrame(index=folds, columns=cls_idx)\n",
    "\n",
    "for n, (train_indices, val_indices) in enumerate(kfolds, start=1):\n",
    "    train_totals = labels_df.iloc[train_indices].sum()\n",
    "    val_totals = labels_df.iloc[val_indices].sum()\n",
    "\n",
    "    # To avoid division by zero, we add a small value (1E-7) to the denominator\n",
    "    ratio = val_totals / (train_totals + 1E-7)\n",
    "    fold_lbl_distrb.loc[f'split_{n}'] = ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = Path(dataset_path / f'{datetime.date.today().isoformat()}_{ksplit}-Fold_Cross-val')\n",
    "save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "images = sorted((dataset_path / 'images').rglob(\"*.jpeg\"))  # change file extension as needed\n",
    "ds_yamls = []\n",
    "\n",
    "for split in folds_df.columns:\n",
    "    # Create directories\n",
    "    split_dir = save_path / split\n",
    "    split_dir.mkdir(parents=True, exist_ok=True)\n",
    "    (split_dir / 'train' / 'images').mkdir(parents=True, exist_ok=True)\n",
    "    (split_dir / 'train' / 'labels').mkdir(parents=True, exist_ok=True)\n",
    "    (split_dir / 'val' / 'images').mkdir(parents=True, exist_ok=True)\n",
    "    (split_dir / 'val' / 'labels').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Create dataset YAML files\n",
    "    dataset_yaml = split_dir / f'{split}_dataset.yaml'\n",
    "    ds_yamls.append(dataset_yaml)\n",
    "\n",
    "    with open(dataset_yaml, 'w') as ds_y:\n",
    "        yaml.safe_dump({\n",
    "            'path': split_dir.as_posix(),\n",
    "            'train': 'train',\n",
    "            'val': 'val',\n",
    "            'names': classes\n",
    "        }, ds_y)\n",
    "for image, label in zip(images, labels):\n",
    "    for split, k_split in folds_df.loc[image.stem].items():\n",
    "        # Destination directory\n",
    "        img_to_path = save_path / split / k_split / 'images'\n",
    "        lbl_to_path = save_path / split / k_split / 'labels'\n",
    "\n",
    "        # Copy image and label files to new directory\n",
    "        # Might throw a SamefileError if file already exists\n",
    "        shutil.copy(image, img_to_path / image.name)\n",
    "        shutil.copy(label, lbl_to_path / label.name)\n",
    "folds_df.to_csv(save_path / \"kfold_datasplit.csv\")\n",
    "fold_lbl_distrb.to_csv(save_path / \"kfold_label_distribution.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/saidinesh/Desktop/Projects/yolov5/\n",
    "from ultralytics import YOLO\n",
    "weights_path = 'yolov5s.pt'\n",
    "model = YOLO(weights_path, task='detect')\n",
    "results = {}\n",
    "for k in range(1,5):\n",
    "    dataset_yaml = f'datasets/train/2023-08-30_5-Fold_Cross-val/split_{k+1}/split_{k+1}_dataset.yaml' #ds_yamls[k]\n",
    "    model.train(data=dataset_yaml,name = f'yolo-v5s-base_fold_{k}',device=0)  # Include any training arguments\n",
    "    results[k] = model.metrics  # save output metrics for further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predictions exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/saidinesh/Desktop/Projects/yolov5\n",
      "\u001b[34m\u001b[1mval: \u001b[0mdata=datasets/dataset.yaml, weights=['runs/train/baseline-yolov5s/weights/last.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=1, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
      "YOLOv5 üöÄ v7.0-211-g94e943e Python-3.9.16 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7982MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7026307 parameters, 0 gradients, 15.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/saidinesh/Desktop/Projects/yolov5/datasets/val/labels.cache.\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è /home/saidinesh/Desktop/Projects/yolov5/datasets/val/images/train_10160.jpeg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1289]\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        515        517      0.484      0.454      0.469      0.386\n",
      "            albopictus        515        230      0.897      0.912       0.92      0.744\n",
      "                 culex        515        229      0.906       0.93      0.942      0.773\n",
      "             anopheles        515          4          0          0          0          0\n",
      "              culiseta        515         31      0.665      0.645      0.681      0.562\n",
      "    japonicus/koreicus        515         21      0.434      0.238      0.274      0.235\n",
      "               aegypti        515          2          0          0          0          0\n",
      "Speed: 0.2ms pre-process, 4.5ms inference, 1.3ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/exp2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%cd /home/saidinesh/Desktop/Projects/yolov5/\n",
    "!python val.py --weights runs/train/baseline-yolov5s/weights/last.pt  \\\n",
    "    --data datasets/dataset.yaml  --max-det 1\\\n",
    "    #--source datasets/val/images  \\\n",
    "    --img 640 --half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# Run the model on GPU if it is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train/baseline-yolov5s/weights/last.pt')\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/saidinesh/Desktop/Projects/yolov5/\n",
    "import fiftyone as fo\n",
    "name = \"my-dataset\"\n",
    "dataset_dir = \"datasets/\"\n",
    "\n",
    "# The splits to load\n",
    "splits = [\"train\", \"val\"]\n",
    "try:\n",
    "    dataset = fo.load_dataset(name)\n",
    "    dataset.delete()\n",
    "except:\n",
    "    pass\n",
    "dataset = fo.Dataset(name)    \n",
    "for split in splits:\n",
    "    dataset.add_dir(\n",
    "        dataset_dir=dataset_dir,\n",
    "        dataset_type=fo.types.YOLOv5Dataset,\n",
    "        split=split,\n",
    "        tags=split,\n",
    ")\n",
    "\n",
    "# Get some summary information about the dataset\n",
    "print(dataset.info)\n",
    "print(dataset.stats)\n",
    "session = fo.Session(dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_view.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmdet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
